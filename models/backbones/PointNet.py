import torch
import torch.nn as nn
from torch.autograd import Variable
import numpy as np
import torch.nn.functional as F

#STN3dï¼ˆSpatial Transformer Network for 3Dï¼‰æ˜¯ä¸€ä¸ª3Dç©ºé—´å˜æ¢æ¨¡å—ã€‚å…¶ä¸»è¦åŠŸèƒ½æ˜¯å­¦ä¹ è¾“å…¥ç‚¹äº‘çš„ç©ºé—´å˜æ¢çŸ©é˜µï¼Œç”¨ä»¥å¯¹ç‚¹äº‘è¿›è¡Œå¯¹é½æˆ–æ ‡å‡†åŒ–ï¼Œä»è€Œæé«˜æ¨¡å‹å¯¹æ—‹è½¬å’Œå¹³ç§»å˜åŒ–çš„é²æ£’æ€§

class STN3d(nn.Module):
    def __init__(self, num_points=2500, k=3, use_bn=True): #è¾“å…¥ç‚¹äº‘çš„ç‚¹æ•°ï¼Œé»˜è®¤ä¸º 2500
        super(STN3d, self).__init__()
        self.k = k #ç©ºé—´å˜æ¢çŸ©é˜µçš„å¤§å°ï¼Œé»˜è®¤ä¸º 3ï¼ˆè¡¨ç¤º3Ã—3å˜æ¢çŸ©é˜µï¼‰
        self.kernel_size = 3 if k == 3 else 1
        self.channels = 1 if k == 3 else k
        self.num_points = num_points
        self.use_bn = use_bn #æ˜¯å¦åœ¨ç½‘ç»œä¸­ä½¿ç”¨æ‰¹é‡å½’ä¸€åŒ–ï¼ˆBatch Normalizationï¼‰ï¼Œé»˜è®¤å¯ç”¨

        #å·ç§¯å±‚
        #ç¬¬ä¸€å±‚å°†è¾“å…¥ç‚¹ç‰¹å¾æ˜ å°„åˆ°64ç»´ï¼Œç¬¬äºŒå±‚æ˜ å°„åˆ°128ç»´ï¼Œç¬¬ä¸‰å±‚æ˜ å°„åˆ°1024ç»´
        self.conv1 = torch.nn.Conv2d(self.channels, 64, (1, self.kernel_size))
        self.conv2 = torch.nn.Conv2d(64, 128, (1, 1))
        self.conv3 = torch.nn.Conv2d(128, 1024, (1, 1))
        #æ± åŒ–å±‚ï¼ˆmp1ï¼‰ ä½¿ç”¨å…¨å±€æœ€å¤§æ± åŒ–ï¼ˆMaxPool2dï¼‰ï¼Œå°†ç‰¹å¾ç»´åº¦ç¼©å‡ä¸º 1024
        self.mp1 = torch.nn.MaxPool2d((num_points, 1), 1)
        #å…¨è¿æ¥å±‚ï¼ˆfc1, fc2, fc3ï¼‰ ç”¨äºå°†ç‰¹å¾å‹ç¼©å¹¶æœ€ç»ˆé¢„æµ‹ kÃ—k çš„ç©ºé—´å˜æ¢çŸ©é˜µ fc3 çš„åˆå§‹æƒé‡å’Œåç½®è®¾ä¸ºé›¶ï¼Œä¿è¯åˆå§‹è¾“å‡ºä¸ºå•ä½çŸ©é˜µ
        self.fc1 = nn.Linear(1024, 512)
        self.fc2 = nn.Linear(512, 256)
        self.fc3 = nn.Linear(256, k*k)
        self.fc3.weight.data.zero_()
        self.fc3.bias.data.zero_()
        self.relu = nn.ReLU()

        if use_bn:
            #æ‰¹é‡å½’ä¸€åŒ–å±‚ è‹¥å¯ç”¨æ‰¹é‡å½’ä¸€åŒ–ï¼Œåˆ™å¯¹æ¯ä¸€å±‚çš„è¾“å‡ºè¿›è¡Œå½’ä¸€åŒ–ä»¥åŠ é€Ÿè®­ç»ƒå’Œæé«˜ç¨³å®šæ€§
            self.bn1 = nn.BatchNorm2d(64)
            self.bn2 = nn.BatchNorm2d(128)
            self.bn3 = nn.BatchNorm2d(1024)
            self.bn4 = nn.BatchNorm1d(512)
            self.bn5 = nn.BatchNorm1d(256)

    def forward(self, x):
        batchsize = x.size()[0]
        if self.use_bn:
            x = F.relu(self.bn1(self.conv1(x)))
            x = F.relu(self.bn2(self.conv2(x)))
            x = F.relu(self.bn3(self.conv3(x)))
        else:
            x = F.relu(self.conv1(x))
            x = F.relu(self.conv2(x))
            x = F.relu(self.conv3(x))
        x = self.mp1(x)
        x = x.view(-1, 1024)

        if self.use_bn:
            x = F.relu(self.bn4(self.fc1(x)))
            x = F.relu(self.bn5(self.fc2(x)))
        else:
            x = F.relu(self.fc1(x))
            x = F.relu(self.fc2(x))
        x = self.fc3(x)

        iden = Variable(torch.from_numpy(np.eye(self.k).astype(np.float32))).view(
            1, self.k*self.k).repeat(batchsize, 1)
        if x.is_cuda:
            iden = iden.cuda()
        x = x + iden
        x = x.view(-1, self.k, self.k)
        return x
"""
è¾“å…¥å¼ é‡ x é€šè¿‡å·ç§¯å±‚å’Œæ± åŒ–å±‚æå–å…¨å±€ç‰¹å¾
ç‰¹å¾é€šè¿‡å…¨è¿æ¥å±‚ç”Ÿæˆå˜æ¢çŸ©é˜µ x
åŠ å…¥å•ä½çŸ©é˜µï¼ˆidenï¼‰ä½œä¸ºåˆå§‹åŒ–åç§»ï¼Œä»¥ç¡®ä¿ç½‘ç»œç¨³å®šè®­ç»ƒ
è¾“å‡ºæœ€ç»ˆçš„ kÃ—k å˜æ¢çŸ©é˜µ
"""
#PointNetfeat æ˜¯ PointNet ä¸­çš„ç‰¹å¾æå–æ¨¡å—ï¼Œç”¨äºä»ç‚¹äº‘ä¸­æå–å…¨å±€å’Œå±€éƒ¨ç‰¹å¾ã€‚è¯¥æ¨¡å—å¯ä»¥é€‰æ‹©è¾“å‡ºå…¨å±€ç‰¹å¾æˆ–æ¯ä¸ªç‚¹çš„å±€éƒ¨ç‰¹å¾
class PointNetfeat(nn.Module): #æ˜¯å¦è¿”å›å…¨å±€ç‰¹å¾ï¼ˆé»˜è®¤è¿”å›å…¨å±€ç‰¹å¾ï¼‰ æ˜¯å¦å¯¹ç‰¹å¾è¿›è¡ŒäºŒæ¬¡ç©ºé—´å˜æ¢ æ˜¯å¦åœ¨æœ€åæ‰§è¡Œå…¨å±€æœ€å¤§æ± åŒ–
    def __init__(self, num_points=2500, global_feat=True, feature_transform=False, max_pool=True):
        super(PointNetfeat, self).__init__()
        self.stn = STN3d(num_points=num_points, k=3, use_bn=False) #ä½¿ç”¨ STN3d å­¦ä¹ ç‚¹äº‘çš„3Då˜æ¢å’Œç‰¹å¾å˜æ¢
        self.feature_trans = STN3d(num_points=num_points, k=64, use_bn=False)
        self.apply_feature_trans = feature_transform
        #conv1 å°†ç‚¹ä»3ç»´æ˜ å°„åˆ°64ç»´ã€‚åç»­å·ç§¯å±‚é€æ­¥æå–æ›´æ·±å±‚æ¬¡çš„ç‰¹å¾ï¼ˆ128ç»´åˆ°1024ç»´ï¼‰
        self.conv1 = torch.nn.Conv2d(1, 64, (1, 3))
        self.conv2 = torch.nn.Conv2d(64, 64, (1, 1))
        self.conv3 = torch.nn.Conv2d(64, 64, (1, 1))
        self.conv4 = torch.nn.Conv2d(64, 128, (1, 1))
        self.conv5 = torch.nn.Conv2d(128, 1024, (1, 1))
        #æ‰¹é‡å½’ä¸€åŒ–å±‚
        self.bn1 = nn.BatchNorm2d(64)
        self.bn2 = nn.BatchNorm2d(64)
        self.bn3 = nn.BatchNorm2d(64)
        self.bn4 = nn.BatchNorm2d(128)
        self.bn5 = nn.BatchNorm2d(1024)
        #æ± åŒ–å±‚
        self.mp1 = torch.nn.MaxPool2d((num_points, 1), 1)
        self.num_points = num_points
        self.global_feat = global_feat
        self.max_pool = max_pool

    def forward(self, x):
        batchsize = x.size()[0]
        trans = self.stn(x)
        x = torch.matmul(torch.squeeze(x), trans)
        x = x.view(batchsize, 1, -1, 3)
        x = F.relu(self.bn1(self.conv1(x)))
        x = F.relu(self.bn2(self.conv2(x)))
        pointfeat = x
        if self.apply_feature_trans:
            f_trans = self.feature_trans(x)
            x = torch.squeeze(x)
            if batchsize == 1:
                x = torch.unsqueeze(x, 0)
            x = torch.matmul(x.transpose(1, 2), f_trans)
            x = x.transpose(1, 2).contiguous()
            x = x.view(batchsize, 64, -1, 1)
        x = F.relu(self.bn3(self.conv3(x)))
        x = F.relu(self.bn4(self.conv4(x)))
        x = self.bn5(self.conv5(x))
        if not self.max_pool:
            return x
        else:
            x = self.mp1(x)
            x = x.view(-1, 1024)
            if self.global_feat:
                return x, trans
            else:
                x = x.view(-1, 1024, 1).repeat(1, 1, self.num_points)
                return torch.cat([x, pointfeat], 1), trans



"""
è¾“å…¥ç‚¹äº‘å¼ é‡ ğ‘¥ç»´åº¦ä¸º (ğµ,ğ‘,3)ï¼Œå³æ‰¹é‡å¤§å°ä¸º Bï¼Œç‚¹æ•°ä¸º Nï¼Œæ¯ä¸ªç‚¹æœ‰3ä¸ªåæ ‡ã€‚
è¾“å‡ºï¼š
å¦‚æœ global_feat=Trueï¼Œè¾“å‡ºå½¢çŠ¶ä¸º (B,1024)ã€‚
å¦‚æœ global_feat=Falseï¼Œè¾“å‡ºå½¢çŠ¶ä¸º (ğµ,1088,ğ‘)
(B,1088,N)ï¼Œå…¶ä¸­ 1088 æ˜¯ 1024ï¼ˆå…¨å±€ç‰¹å¾ï¼‰åŠ ä¸Š 64ï¼ˆå±€éƒ¨ç‰¹å¾ï¼‰
"""
